
zeta.actor.cluster += "b1:2551"
zeta.actor.cluster += "b2:2551"
play.akka.actor-system = "ClusterSystem"



akka {

  actor.provider = "akka.cluster.ClusterActorRefProvider"


  extensions += "akka.cluster.client.ClusterClientReceptionist"
  extensions += "akka.cluster.metrics.ClusterMetricsExtension"
  extensions += "akka.cluster.pubsub.DistributedPubSub"


  cluster {
    metrics.enabled = off
    seed-nodes = []
    # "akka.tcp://ClusterSystem@127.0.0.1:2551"
    #min-nr-of-members = 2
    auto-down-unreachable-after = 10s


    failure-detector {
      threshold = 12
      acceptable-heartbeat-pause = 60s
      heartbeat-interval = 5s
      heartbeat-request {
        expected-response-after = 20s
      }
    }

    # Settings for the ClusterShardingExtension
    sharding {

      # The extension creates a top level actor with this name in top level system scope,
      # e.g. '/system/sharding'
      #guardian-name = sharding

      # Specifies that entities runs on cluster nodes with a specific role.
      # If the role is not specified (or empty) all nodes in the cluster are used.
      role = "developer"

      # When this is set to 'on' the active entity actors will automatically be restarted
      # upon Shard restart. i.e. if the Shard is started on a different ShardRegion
      # due to rebalance or crash.
      remember-entities = on

      # If the coordinator can't store state changes it will be stopped
      # and started again after this duration, with an exponential back-off
      # of up to 5 times this duration.
      coordinator-failure-backoff = 5 s

      # The ShardRegion retries registration and shard location requests to the
      # ShardCoordinator with this interval if it does not reply.
      retry-interval = 2 s

      # Maximum number of messages that are buffered by a ShardRegion actor.
      buffer-size = 100000

      # Timeout of the shard rebalancing process.
      handoff-timeout = 60 s

      # Time given to a region to acknowledge it's hosting a shard.
      shard-start-timeout = 10 s

      # If the shard is remembering entities and can't store state changes
      # will be stopped and then started again after this duration. Any messages
      # sent to an affected entity may be lost in this process.
      shard-failure-backoff = 10 s

      # If the shard is remembering entities and an entity stops itself without
      # using passivate. The entity will be restarted after this duration or when
      # the next message for it is received, which ever occurs first.
      entity-restart-backoff = 10 s

      # Rebalance check is performed periodically with this interval.
      rebalance-interval = 10 s

      # Absolute path to the journal plugin configuration entity that is to be
      # used for the internal persistence of ClusterSharding. If not defined
      # the default journal plugin is used. Note that this is not related to
      # persistence used by the entity actors.
      #journal-plugin-id = ""

      # Absolute path to the snapshot plugin configuration entity that is to be
      # used for the internal persistence of ClusterSharding. If not defined
      # the default snapshot plugin is used. Note that this is not related to
      # persistence used by the entity actors.
      #snapshot-plugin-id = ""

      # Parameter which determines how the coordinator will be store a state
      # valid values either "persistence" or "ddata"
      # The "ddata" mode is experimental, since it depends on the experimental
      # module akka-distributed-data-experimental.
      state-store-mode = "persistence"

      # The shard saves persistent snapshots after this number of persistent
      # events. Snapshots are used to reduce recovery times.
      snapshot-after = 1000

      # Setting for the default shard allocation strategy
      least-shard-allocation-strategy {
        # Threshold of how large the difference between most and least number of
        # allocated shards must be to begin the rebalancing.
        rebalance-threshold = 10

        # The number of ongoing rebalancing processes is limited to this number.
        max-simultaneous-rebalance = 3
      }

      # Timeout of waiting the initial distributed state (an initial state will be queried again if the timeout happened)
      # works only for state-store-mode = "ddata"
      waiting-for-state-timeout = 5 s

      # Timeout of waiting for update the distributed state (update will be retried if the timeout happened)
      # works only for state-store-mode = "ddata"
      updating-state-timeout = 5 s

      # The shard uses this strategy to determines how to recover the underlying entity actors. The strategy is only used
      # by the persistent shard when rebalancing or restarting. The value can either be "all" or "constant". The "all"
      # strategy start all the underlying entity actors at the same time. The constant strategy will start the underlying
      # entity actors at a fix rate. The default strategy "all".
      entity-recovery-strategy = "all"

      # Default settings for the constant rate entity recovery strategy
      entity-recovery-constant-rate-strategy {
        # Sets the frequency at which a batch of entity actors is started.
        frequency = 100 ms
        # Sets the number of entity actors to be restart at a particular interval
        number-of-entities = 5
      }

      # Settings for the coordinator singleton. Same layout as akka.cluster.singleton.
      # The "role" of the singleton configuration is not used. The singleton role will
      # be the same as "akka.cluster.sharding.role".
      coordinator-singleton = ${akka.cluster.singleton}

      # The id of the dispatcher to use for ClusterSharding actors.
      # If not specified default dispatcher is used.
      # If specified you need to define the settings of the actual dispatcher.
      # This dispatcher for the entity actors is defined by the user provided
      # Props, i.e. this dispatcher is not used for the entity actors.
      use-dispatcher = ""
    }
  }
}

# Play mailer
play {
  mailer {
    host = smtp.gmail.com
    from = "iodfjvio@gmail.com"
    ssl = true
    port = 465
    user = "iodfjvio@gmail.com"
    password = jVcSwooo
    debug = true
  }

  # Secret key
  # ~~~~~
  # The secret key is used to secure cryptographics functions.
  # If you deploy your application to several instances be sure to use the same key!
  crypto {
    secret = ${APPLICATION_SECRET}
  }
}
include "shared.conf"
